{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Fragmenstein\n",
    "#@markdown Fragmenstein is a position-based fragment-merging python3 tool.\n",
    "#@markdown In its merging/linking operation, under the coordination of the class Victor, \n",
    "#@markdown the class Monster finds spatially overlapping atoms and stitches them together (with RDKit),\n",
    "#@markdown then the class Igor reanimates (minimises in PyRosetta) them within the protein site restraining the atoms\n",
    "#@markdown to original positions.\n",
    "#@markdown As this compound may not be purchasable, one can use the placement operation to\n",
    "#@markdown make a stitched together molecule based a template.\n",
    "\n",
    "#@markdown This notebook does sevaral operations.\n",
    "#@markdown It optionally minimises the template structure,\n",
    "#@markdown and optionally extracts the hits from provided PDB structures.\n",
    "#@markdown It combines combinatorially the provided hits\n",
    "#@markdown It then searches for the most similar molecules to the user chosen molecule\n",
    "#@markdown in the Enamine Real database (via the API John Irwin's SmallWorld server)\n",
    "#@markdown and places them.\n",
    "\n",
    "#@markdown NB Whereas Fragmenstein can deal with covalent ligands\n",
    "#@markdown and can interconvert a few cysteine reactive warheads\n",
    "#@markdown this notebook does not do any of that due to corner case mayhem.\n",
    "\n",
    "#@markdown Fragmenstein can _partially_ work without PyRosetta\n",
    "\n",
    "#@markdown This notebook from [https://github.com/matteoferla/Fragmenstein).\n",
    "\n",
    "#@markdown It can be opened in Colabs via [https://colab.research.google.com/github/matteoferla/Fragmenstein/blob/main/colabs/colabs-pyrosetta-migrate_ligands.ipynb](https://colab.research.google.com/github/matteoferla/pyrosetta_help/blob/main/colabs/colabs-pyrosetta-migrate_ligands.ipynb)\n",
    "\n",
    "#@markdown See also:\n",
    "\n",
    "#@markdown * https://github.com/matteoferla/Fragmenstein\n",
    "#@markdown * https://github.com/matteoferla/Python_SmallWorld_API\n",
    "#@markdown * https://github.com/matteoferla/pyrosetta_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Installation\n",
    "\n",
    "# Muppet-proofing: are we in colab?\n",
    "shell_name = get_ipython().__class__.__name__\n",
    "if shell_name == 'Shell':\n",
    "    modality = 'colab'\n",
    "elif shell_name == 'ZMQInteractiveShell':\n",
    "    modality = 'jupyter'\n",
    "elif shell_name == 'TerminalInteractiveShell':\n",
    "    raise RuntimeError('This is a colabs notebook. Why are you running it in the terminal?')\n",
    "else:\n",
    "    raise RuntimeError(f'This is a colabs notebook. not a {shell_name}')\n",
    "\n",
    "#@markdown ### Quicker loading option via Google Drive\n",
    "#@markdown Installing PyRosetta with optional backup to your drive (way quicker next time!).\n",
    "#@markdown Note that PyRosetta occupies some 10 GB, so you'll need to be on the 100 GB plan of Google Drive (it's one pound a month).\n",
    "\n",
    "#@markdown NB. If `use_drive` is True, you will be prompted to give permission to \n",
    "#@markdown use Google Drive —_always_ remember to check strangers code against data theft: search and look for all instances of `http`, `requests` and `post` in the code.\n",
    "\n",
    "#@markdown ### Download PyRosetta\n",
    "#@markdown The following is not the real username and password. However, the format is similar.\n",
    "username = 'boltzmann' #@param {type:\"string\"}\n",
    "username.strip().lower()\n",
    "password = 'constant' #@param {type:\"string\"}\n",
    "#@markdown Are these the \"normal\" common credentials?\n",
    "#@markdown If so their hash will be checked beforehand to check if they are correct.\n",
    "hash_comparision_required = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown Release to install:\n",
    "_release = 'release-295' #@param {type:\"string\"}\n",
    "#@markdown Use Google Drive for PyRosetta (way faster next time, but takes up space)\n",
    "#@markdown (NB. You may be prompted to follow a link and possibly authenticate and then copy a code into a box\n",
    "use_drive = True #@param {type:\"boolean\"}\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "import importlib\n",
    "import pip\n",
    "import hashlib\n",
    "\n",
    "def install_and_import(package_name: str, \n",
    "                       pypi_name: Optional[str]=None,\n",
    "                       alias_name: Optional[str]=None):\n",
    "    \"\"\"If the module has a different name in pypi (`pypi_name`) \n",
    "    than its import name (`package_name`), specify it.\n",
    "    \n",
    "         pip install pypi_name\n",
    "         import package_name as alias_name\n",
    "    \"\"\"\n",
    "    if pypi_name is None:\n",
    "        pypi_name = package_name\n",
    "    if as_name is None:\n",
    "        as_name = package_name\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "    except ImportError as error:\n",
    "        if error.name != package_name:\n",
    "            # these are not the droids we are looking for\n",
    "            raise ImportError(f'Import of {package_name} requires module {name}...', name=error.name)\n",
    "        # I will go to hell for this, but shmeh:\n",
    "        pip._internal.cli.main.main(['install', pypi_name])\n",
    "    globals()[as_name] = importlib.import_module(package_name)\n",
    "\n",
    "# ================================================================\n",
    "# install pyrosetta\n",
    "\n",
    "if modality == 'colab':\n",
    "    if use_drive:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        _path = '/content/drive/MyDrive'\n",
    "        os.chdir(_path)\n",
    "    else:\n",
    "        _path = '/content'\n",
    "else:\n",
    "    # jupyter\n",
    "    _path = './'\n",
    "\n",
    "# install pyrosetta\n",
    "try:\n",
    "    # is pyrosetta installed?\n",
    "    import pyrosetta\n",
    "except ImportError: # pyrosetta is not installed.\n",
    "    # is pyrosetta not downloaded?\n",
    "    if not any(['PyRosetta4.Release' in filename for filename in os.listdir()]):\n",
    "        # check if hash is right.\n",
    "        if hash_comparision_required:\n",
    "            # verify the username and password are correct without actually knowing them.\n",
    "            hashed_username = hashlib.sha256(username.encode()).hexdigest()\n",
    "            hashed_password = hashlib.sha256(password.encode()).hexdigest()\n",
    "            expected_hashed_username = 'cf6f296b8145262b22721e52e2edec13ce57af8c6fc990c8ae1a4aa3e50ae40e'\n",
    "            expected_hashed_password = '45066dd976d8bf0c05dc8dd4d58727945c3437e6eb361ba9870097968db7a0da'\n",
    "            assert hashed_username == expected_hashed_username, 'The hash of the username is not as expected'\n",
    "            assert hashed_password == expected_hashed_password, 'The hash of the password is not as expected'\n",
    "        # download tar in the scratch folder... but extract to whatever the working path is!\n",
    "        assert not os.system(f'curl -u {username}:{password} https://graylab.jhu.edu/download/PyRosetta4/archive/release/PyRosetta4.Release.python{py_version}.ubuntu/PyRosetta4.Release.python{py_version}.ubuntu.{_release}.tar.bz2 -o /content/a.tar.bz2')\n",
    "        assert not os.system('tar -xf /content/a.tar.bz2') # destination --> _path\n",
    "    assert not os.system(f'pip3 install -e {_path}/PyRosetta4.Release.python{py_version}.ubuntu.{_release}/setup/')\n",
    "\n",
    "# ================================================================\n",
    "# install other stuff\n",
    "install_and_import(package_name='Bio', pypi_name='biopython')\n",
    "install_and_import(package_name='rdkit', pypi_name='rdkit-pypi')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "install_and_import(package_name='pyrosetta_help', pypi_name='pyrosetta-help', alias_name='ph')\n",
    "install_and_import(package_name='rdkit_to_params', pypi_name='rdkit-to-params')\n",
    "install_and_import(package_name='smallworld_api', pypi_name='smallworld-api')\n",
    "install_and_import('fragmenstein')\n",
    "# refresh imports\n",
    "import site\n",
    "site.main()\n",
    "\n",
    "# ================================================================\n",
    "# make folders in _path\n",
    "working_folder = 'fragmenstein_data'\n",
    "input_folder = 'input'\n",
    "output_folder = 'output'\n",
    "if not os.path.exists(working_folder):\n",
    "    os.mkdir(working_folder)\n",
    "    os.chdir('fragmenstein_data')\n",
    "for folder in (input_folder, output_folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "# ================================================================\n",
    "# 3D viewer\n",
    "\n",
    "install_and_import('py3Dmol')\n",
    "from typing import *\n",
    "from rdkit import Chem\n",
    "\n",
    "def stylize(representation:str, color:str) -> Dict[str, Dict[str, Dict[str, str]]]:\n",
    "    if 'carbon' in color.lower():\n",
    "        return dict(style={representation: {'colorscheme': color}})\n",
    "    else:\n",
    "        return dict(style={representation: {'color': color}})\n",
    "\n",
    "def make_3Dview(template_pdbblock, colormols:Dict[str, List[Chem.Mol]]) -> py3Dmol.view:\n",
    "    \"\"\"\n",
    "    colormols is a diction of color/colorscheme to list of mols.\n",
    "    \"\"\"\n",
    "    view = py3Dmol.view(js=\"https://3dmol.org/build/3Dmol.js\")\n",
    "    view.addModel(template_pdbblock, \"pdb\", stylize('cartoon','gainsboro') )\n",
    "    view.setStyle(dict(hetflag=True), stylize('stick', 'whiteCarbon') )\n",
    "    for color, mols in colormols.items():\n",
    "        for mol in mols:\n",
    "            view.addModel(Chem.MolToMolBlock(mol), \"mol\", stylize('stick', color) )\n",
    "    view.zoomTo(dict(hetflag=True))\n",
    "    return view\n",
    "\n",
    "# ================================================================\n",
    "# mol grid\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from IPython.display import display\n",
    "\n",
    "class HorizontalMols:\n",
    "    def __init__(self, *args):\n",
    "        self.mols = [self._convert(arg) for arg in args]\n",
    "        \n",
    "    def _convert(self, mol_or_smiles: Union[str, Chem.Mol]) -> Chem.Mol:\n",
    "        if isinstance(mol_or_smiles, Chem.Mol):\n",
    "            return mol_or_smiles\n",
    "        elif isinstance(mol_or_smiles, str):\n",
    "            return Chem.MolFromSmiles(mol_or_smiles)\n",
    "        elif isinstance(mol_or_smiles, bytes):\n",
    "            return Chem.Mol(mol_or_smiles)\n",
    "        elif mol_or_smiles is None:\n",
    "            return Chem.Mol()\n",
    "        else:\n",
    "            raise TypeError(f'What is {mol_or_smiles}?')\n",
    "        \n",
    "    def _mol_to_svg(self, mol: Chem.Mol) -> str:\n",
    "        d2d = Draw.rdMolDraw2D.MolDraw2DSVG(250, 200)\n",
    "        mol2 = Chem.Mol(mol)\n",
    "        AllChem.Compute2DCoords(mol2)\n",
    "        d2d.DrawMolecule(mol2)\n",
    "        d2d.FinishDrawing()\n",
    "        return d2d.GetDrawingText()\n",
    "    \n",
    "    def _get_mol_name(self, mol: Chem.Mol) -> str:\n",
    "        if mol.HasProp('_Name'):\n",
    "            return mol.GetProp('_Name')\n",
    "        else:\n",
    "            return '「 no name 」'\n",
    "\n",
    "    def _get_mol_details(self, mol: Chem.Mol) -> Dict[str, str]:\n",
    "        return dict(name=self._get_mol_name(mol),\n",
    "                    smiles=Chem.MolToSmiles(mol),\n",
    "                    svg=self._mol_to_svg(mol)\n",
    "                   )\n",
    "        \n",
    "    def _repr_html_(self):\n",
    "        inner = '<h4>{name}<h4><p>{smiles}</p>{svg}'\n",
    "        template = f'<div style=\"float: left; padding: 10px;\">{inner}</div>'\n",
    "        return \"\\n\".join(template.format(**self._get_mol_details(mol)) for mol in self.mols)\n",
    "    \n",
    "    def show(self) -> None:\n",
    "        from IPython.display import display\n",
    "        display(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Start PyRosetta\n",
    "#@markdown Leave alone and just run it. \n",
    "#@markdown Only one that you might want to change is `ignore_waters`\n",
    "#@markdown as merging a ligand with its watershell may be a reasonable thing to do\n",
    "#@markdown in extreme circumstances —like not even Chuck Norris could find a followup.\n",
    "import pyrosetta, logging\n",
    "import pyrosetta_help as ph\n",
    "\n",
    "#@markdown Do not optimise hydrogen on loading:\n",
    "no_optH = False #@param {type:\"boolean\"}\n",
    "#@markdown Ignore (True) or raise error (False) if novel residue (e.g. ligand) —  **don't tick this**.\n",
    "ignore_unrecognized_res=False  #@param {type:\"boolean\"}\n",
    "#@markdown Use autogenerated PDB residues are often weird (bad geometry, wrong match, protonated etc.): —best do it properly and parameterise it, so **don't tick this**.\n",
    "load_PDB_components=False  #@param {type:\"boolean\"}\n",
    "#@markdown Ignore all waters:\n",
    "ignore_waters=True  #@param {type:\"boolean\"}\n",
    "\n",
    "extra_options= ph.make_option_string(no_optH=no_optH,\n",
    "                                  ex1=None,\n",
    "                                  ex2=None,\n",
    "                                  ignore_unrecognized_res=ignore_unrecognized_res,\n",
    "                                  load_PDB_components=load_PDB_components,\n",
    "                                  ignore_waters=ignore_waters)\n",
    "\n",
    "# capture to log\n",
    "logger = ph.configure_logger()\n",
    "logger.handlers[0].setLevel(logging.WARNING) # logging.WARNING = 30\n",
    "pyrosetta.init(extra_options=extra_options, set_logging_handler=True)\n",
    "logger = logging.getLogger('rosetta')\n",
    "logger.handlers[0].setLevel(logging.WARNING) # logging.WARNING = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Upload Template model\n",
    "#@markdown Upload PDB file of the template model used for placing the merger.\n",
    "#@markdown Suggestion: use a model bound to the native ligand or similar\n",
    "#@markdown as the side chains will be poised for action!\n",
    "#@markdown NB. this PDB and those of the hits need to be superposed.\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "assert len(uploaded) ==1, 'Upload only one template. Hits later.'\n",
    "pdbblock = list(uploaded.values())[0]\n",
    "if isinstance(pdbblock, bytes): # dont recall what format are txt sent as...\n",
    "    pdbblock = pdbblock.decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optionally prepare it (1/3)\n",
    "#@markdown This will be done by \n",
    "\n",
    "#@markdown 1. loading it in PyRosetta\n",
    "#@markdown 2. Optionally energy minimising around a target\n",
    "#@markdown 3. Optionally remove some molecules\n",
    "\n",
    "#@markdown ### Step 1\n",
    "#@markdown If the model has novel ligands, they will be loaded.\n",
    "#@markdown But to do this a residue type  (=topology) needs to be made or loaded.\n",
    "#@markdown These are saved as \"params files\".\n",
    "#@markdown These following options control both the \"acceptor\" and \"donor\" poses (if uploaded).\n",
    "#@markdown ### Params\n",
    "#@markdown * Some compounds are parameterised in the database folder of rosetta,\n",
    "#@markdown others in the PDB component database (if loaded).\n",
    "#@markdown * Uses the params defined in the cell of the acceptor pose.\n",
    "#@markdown * If there is no topology avalaible one will be made.\n",
    "#@markdown * If a params file is present in the working folder it will use it.\n",
    "#@markdown * See below or visit https://params.mutanalyst.com/ to generate them (upload the with the folder icon on the left).\n",
    "\n",
    "#@markdown This forces it (a bit silly):\n",
    "force_parameterisation = False  #@param {type:\"boolean\"}\n",
    "#@markdown If it needs to be parameterised make it protonated for pH 7?\n",
    "neutralise_params=True #@param {type:\"boolean\"}\n",
    "save_params=True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown If a params file is present in the working folder it will use it.\n",
    "#@markdown Leave this blank... otherwise  (comma separated w/ no rando spaces):\n",
    "extra_params_files_to_use = '' #@param {type:\"string\"}\n",
    "extra_params = [f for f in extra_params_files_to_use.split(',') if f]\n",
    "use_all_folder_params= ''  #@param {type:\"boolean\"}\n",
    "if use_all_folder_params:\n",
    "    present_params = [filename for filename in os.listdir() if os.path.splitext(filename) == '.params']\n",
    "else:\n",
    "    present_params = []\n",
    "print('loading pose...')\n",
    "template_pose = ph.ligands.load.parameterised_pose_from_pdbblock(pdbblock,\n",
    "                                 wanted_ligands = [],\n",
    "                                 force_parameterisation=force_parameterisation,\n",
    "                                 neutralise_params=neutralise_params,\n",
    "                                 save_params=save_params,\n",
    "                                 overriding_params=extra_params+present_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optional energy minimisation around a target (2/3)\n",
    "#@markdown (Requires previous cell run)\n",
    "assert 'template_pose' in globals(), 'Step 1 was not run'\n",
    "\n",
    "#@markdown If use density map is true, you will be prompted to upload a density map.\n",
    "#@markdown Upload a f0fc ccp4 or a mrc map. (not a ccp4 difference map, \n",
    "#@markdown a mtz reciprocal space map or a pirate treasure map)\n",
    "#@markdown The map needs to be in the same position as the template.\n",
    "use_density_map = True  #@param {type:\"boolean\"}\n",
    "#@markdown The whole structure could be minimised, but that would be pointless costly timewise\n",
    "#@markdown for this task.\n",
    "#@markdown Specify what residue (amino acid or ligand) to centre around \n",
    "center_residue_index = 1  #@param {type:\"integer\"}\n",
    "center_residue_chain = 'A'  #@param {type:\"string\"}\n",
    "center_index : int = template_pose.pdb_info().pdb2pose(res=center_residue_index, chain=center_residue_chain)\n",
    "assert center_index != 0, 'That residue does not exist!'\n",
    "\n",
    "#@markdown Specify which neighbouring residues to select in one of three ways:\n",
    "\n",
    "#@markdown (1) Cutoff distance for the neighbouring residues (in Ångströms) (centroid to centroid)?\n",
    "#@markdown set to zero to not use.\n",
    "neighborhood_radius = 1  #@param {type:\"integer\"}\n",
    "#@markdown (2) Cutoff distance for the neighbouring residues (in Ångströms) (closest atom to closest atom)?\n",
    "#@markdown set to zero to not use.\n",
    "cc_neighborhood_radius = 0  #@param {type:\"integer\"}\n",
    "#@markdown (3) Max number of neighbouring residues to choose?\n",
    "#@markdown set to zero to not use.\n",
    "n_neighbors = 0  #@param {type:\"integer\"}\n",
    "\n",
    "#@markdown ## Minimisation\n",
    "#@markdown How many cycles of FastRelax to use? 3–15\n",
    "cycles = 3  #@param {type:\"integer\"}\n",
    "#@markdown to change scorefunctions and so forth edit the code.\n",
    "\n",
    "# Get map\n",
    "if use_density_map:\n",
    "    map_filename = 'uploaded_map.ccp4'\n",
    "    uploaded = files.upload()\n",
    "    assert len(uploaded) ==1, 'wrong number of files (only one plz)'\n",
    "    mapblock = list(uploaded.values())[0]\n",
    "    with open(os.path.join(input_folder, filename), 'wb') as fh:\n",
    "        fh.write(mapblock)\n",
    "    # this can be done with `Igor.relax_with_ED`, but I wanted the option here to do\n",
    "    # it with or without the map\n",
    "    ed = ph.prep_ED(template_pose, map_filename)\n",
    "    assert ed.matchPose(pose) > 0.5, 'This is a rubbish fit. Upload the right map.'\n",
    "    \n",
    "# prep scorefunction\n",
    "scorefxn = pyrosetta.get_fa_scorefxn()\n",
    "if use_density_map:\n",
    "    scorefxn.set_weight(pyrosetta.rosetta.core.scoring.ScoreType.elec_dens_fast,\n",
    "                        30)\n",
    "    \n",
    "# get neighbourhood selector\n",
    "neighborhood_radius = 1  #@param {type:\"integer\"}\n",
    "#@markdown (2) Cutoff distance for the neighbouring residues (in Ångströms) (closest atom to closest atom)?\n",
    "#@markdown set to zero to not use.\n",
    "cc_neighborhood_radius = 0  #@param {type:\"integer\"}\n",
    "#@markdown (3) Max number of neighbouring residues to choose?\n",
    "#@markdown set to zero to not use.\n",
    "n_neighbors = 0\n",
    "selector = pyrosetta.rosetta.core.select.residue_selector\n",
    "resi_sele = selector.ResidueIndexSelector(center_index)\n",
    "if neighborhood_radius != 0:\n",
    "    neighbor_sele = selector.NeighborhoodResidueSelector(resi_sele,\n",
    "                                                         distance=neighborhood_radius,\n",
    "                                                         include_focus_in_subset=True)\n",
    "elif cc_neighborhood_radius != 0:\n",
    "    neighbor_sele = selector.CloseContactResidueSelector()\n",
    "    neighbor_sele.central_residue_group_selector(resi_sele)\n",
    "    neighbor_sele.threshold(cc_neighborhood_radius)\n",
    "elif n_neighbors != 0:\n",
    "    neighbor_sele = selector.NumNeighborsSelector(n_neighbors, 20)\n",
    "    # Ah. True. NumNeighborsSelector does not work in PyRosetta.\n",
    "    raise NotImplementedError\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "# relax\n",
    "movemap = pyrosetta.MoveMap()\n",
    "movemap.set_bb(allow_bb=neighbor_sele.apply(template_pose))\n",
    "movemap.set_chi(allow_chi=neighbor_sele.apply(template_pose))\n",
    "relax = pyrosetta.rosetta.protocols.relax.FastRelax(scorefxn, cycles)\n",
    "relax.set_movemap(movemap)\n",
    "relax.apply(template_pose)\n",
    "\n",
    "pdbblock = ph.get_pdbstr(template_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Optional remove specified stuff (3/3)\n",
    "#@markdown (Requires the cell two back to be run)\n",
    "import re\n",
    "from warnings import warn\n",
    "unwanted_residue_names_raw = 'HOH' #@param {type:\"string\"}\n",
    "unwanted_residue_names_raw = re.sub(r'[\\W]',' ', unwanted_residue_names_raw)\n",
    "unwanted_residue_names = unwanted_residue_names_raw.split()\n",
    "selector = pyrosetta.rosetta.core.select.residue_selector\n",
    "for unwanted_resn in unwanted_residue_names:\n",
    "    sele = selector.ResidueNameSelector()\n",
    "    sele.set_residue_name3(unwanted_resn)\n",
    "    try:\n",
    "        sele.apply(template_pose)\n",
    "    except RuntimeError:\n",
    "        # ResidueNameSelector: XYZ is not a valid residue type name.\n",
    "        warn(f'There is no residue {unwanted_resn}!')\n",
    "    for idx in reversed(list(selector.ResidueVector(  selector.apply(template_pose)  ))):\n",
    "        template_pose.delete_residue_slow(idx)\n",
    "    assert len(selector.ResidueVector(  sele.apply(template_pose)  )) == 0\n",
    "    \n",
    "pdbblock = ph.get_pdbstr(template_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c8/7hcbs7sx56z3bqg9vqhd7c0r0000gp/T/ipykernel_81111/911139085.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Go!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#@title Upload hits or bound hits\n",
    "#@markdown As the decision is based on extension, please no random extensions...\n",
    "#@markdown `mol.try2.mol` is fine, but `mol.molecule` or `mol.mol.txt` are not.\n",
    "\n",
    "#@markdown ### Option 1.\n",
    "#@markdown If you have a single multientry sdf file, upload that.\n",
    "\n",
    "#@markdown ### Option 2.\n",
    "#@markdown If you have multiple mol files, upload those.\n",
    "#@markdown RDKit handles mdl-mol files better than mol2 files.\n",
    "\n",
    "#@markdown ### Option 3.\n",
    "#@markdown If you require your ligand to be extracted from pdb files\n",
    "#@markdown upload those and specify the three-letter code of the ligand\n",
    "#@markdown (this is the 3-letter name within the provided PDB(s) not the intended name for the merger!):\n",
    "ligand_residue_name = 'LIG' #@param {type:\"string\"}\n",
    "#@markdown This latter option is über-recommended if you have a covalently bound ligand\n",
    "#@markdown but your extracted mol files are not or lack bond order.\n",
    "#@markdown Note that you'll have to also upload a SMILES file (`.smi`)\n",
    "#@markdown —this is just a tab separated table of SMILES tab name.\n",
    "\n",
    "#@markdown If your PDB lacks `CONECT` entries (you monster), tick this:\n",
    "proximityBonding = False #@param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "# Go!\n",
    "import os\n",
    "from google.colab import files\n",
    "from rdkit import Chem\n",
    "from typing import *\n",
    "from warnings import warn\n",
    "\n",
    "# get\n",
    "uploaded = files.upload()\n",
    "\n",
    "# sort\n",
    "uploaded_split = {k: [] for k in ('smi', 'sdf', 'mol', 'mol2', 'pdb')}\n",
    "for filename in uploaded:\n",
    "    extension = os.path.splitext(filename)[1].lower()[1:]\n",
    "    if extension not in uploaded_split:\n",
    "        raise ValueError(f'The extension {extension} is not coded for')\n",
    "    data = uploaded[filename] # str or bytes??\n",
    "    if isinstance(data, bytes):\n",
    "        data = data.decode('utf8')\n",
    "    uploaded_split[extension].append( dict(filename=filename, data=data) )\n",
    "\n",
    "# parse SMILES for PDB\n",
    "if uploaded_split['smi']:\n",
    "    # smilesdex? yes, I am going to hell for using not only Hungarian notation in Python, \n",
    "    # but a Pokémon flavoured one.\n",
    "    \n",
    "    smilesdex : Dict[str, str] = dict(map(lambda line: line.split('\\t')[-1::-1],\n",
    "                                         data.replace('\\n\\n','\\n').strip().split('\\n'))\n",
    "                                     )\n",
    "else:\n",
    "    smilesdex = {}\n",
    "    \n",
    "# parsers\n",
    "def read_sdf(filename:str, data:str) -> List[Chem.Mol]:\n",
    "    mols = []\n",
    "    # I am pretty sure there's no way to run `Chem.SDMolSupplier` on a block\n",
    "    with open(os.path.join(input_folder, filename), 'w') as fh:\n",
    "        fh.write(data)\n",
    "    with Chem.SDMolSupplier(filename, removeHs=False) as suppl:\n",
    "        for mol in suppl:\n",
    "            # do I need to add a name??\n",
    "            mols.append(mol)\n",
    "    return mols\n",
    "\n",
    "def read_mol(filename:str, data:str, fun: Callable) -> Chem.Mol:\n",
    "    mol =  fun(data)\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    mol.SetProp('_Name', name)\n",
    "    return mol\n",
    "\n",
    "def get_smiles(filename: str, smiledex: Dict[str, str]) ->  Union[None, str]:\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    if name in smiledex:\n",
    "        return smiledex[name]\n",
    "    else:\n",
    "        warn(f'Could not find matching SMILES to {name}')\n",
    "        return None\n",
    "        \n",
    "\n",
    "# parse molecules...\n",
    "hits = []\n",
    "for entry in uploaded_split['sdf']:\n",
    "    hits.extend( read_sdf(entry['filename'], entry['data']) ) \n",
    "for entry in uploaded_split['mol']:\n",
    "    hits.append( read_mol(entry['filename'], entry['data'], Chem.MolFromMolBlock) )\n",
    "for entry in uploaded_split['mol2']:\n",
    "    hits.append( read_mol(entry['filename'], entry['data'], Chem.MolFromMol2Block) )\n",
    "for entry in uploaded_split['pdb']:\n",
    "    smiles : Union[None, str] = get_smiles(entry['filename'], smiledex)\n",
    "    hits.append( Victor.extract_mol(name=name,\n",
    "                                    block=entry['data'],\n",
    "                                    smiles=smiles,\n",
    "                                    ligand_resn=ligand_residue_name,\n",
    "                                    proximityBonding=proximityBonding,\n",
    "                                    throw_on_error = True)\n",
    "               )\n",
    "    \n",
    "# pollute the directory with files\n",
    "# with Chem.SDWriter(os.path.join(input_folder, 'provided.sdf')) as w:\n",
    "#     for hit in hits:\n",
    "#         w.write(hit)\n",
    "\n",
    "HorizontalMols(hits).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Enter Victor Fragmenstein's laboratory!\n",
    "#@markdown Three step process:\n",
    "\n",
    "#@markdown 1. the hits are combined pairwise\n",
    "#@markdown 2. the mergers are queried in the SmallWorld server against the Enamine REAL DB\n",
    "#@markdown 3. the purchasable similars are placed\n",
    "\n",
    "#@markdown In the documentation the example uses `sqlitedict.SqliteDict`\n",
    "#@markdown as this avoids dramas from segfaults from `KeyboardInterrupt` or funky entries.\n",
    "\n",
    "# Okay, the code below contains some black magic.\n",
    "# a Chem.Mol is sent down the pipe to the subprocess pickled.\n",
    "# But this loses its properties (`mol.HasProp`).\n",
    "# unless this dark ritual is performed:\n",
    "# https://github.com/matteoferla/Fragmenstein/blob/master/documentation/mol_properties.md\n",
    "\n",
    "# =============================================================================================\n",
    "# ## Define the process\n",
    "\n",
    "joining_cutoff = 5 #@param {type:\"integer\"}\n",
    "quick_renanimation = True #@param {type:\"boolean\"}\n",
    "topN_to_pick = 10 #@param {type:\"integer\"}\n",
    "\n",
    "import os, re\n",
    "import pyrosetta, logging\n",
    "from rdkit import Chem\n",
    "from fragmenstein import Victor\n",
    "Victor.work_path = output_folder\n",
    "Victor.monster_throw_on_discard= True  # stop this merger if a fragment cannot be used.\n",
    "Victor.monster_joining_cutoff = joining_cutoff # Å\n",
    "Victor.quick_renanimation = quick_renanimation # for the impatient\n",
    "Victor.error_to_catch = Exception # stop the whole laboratory otherwise\n",
    "#Victor.enable_stdout(logging.ERROR)\n",
    "Victor.enable_logfile(os.path.join(output_folder, 'demo.log'), logging.WARNING)\n",
    "#Victor.log_errors()\n",
    "\n",
    "def combine_subprocess(binary_hits: List[bytes]):\n",
    "    hits : List[Chem.Mol] = [Chem.Mol(bh) for bh in binary_hits]\n",
    "    pyrosetta.distributed.maybe_init(extra_options='-no_optH false -mute all -ignore_unrecognized_res true -load_PDB_components false')\n",
    "    try:\n",
    "        v = Victor(hits=hits,\n",
    "                   pdb_block=pdbblock, # global()\n",
    "                   ligand_resn='LIG',\n",
    "                   ligand_resi='1B',\n",
    "                   covalent_resi='145A', # a random residue is **still** required for the constaint ref atom.\n",
    "                  )\n",
    "        v.combine()\n",
    "        result : dict = v.summarise()\n",
    "        binarize : Callable[[Chem.Mol], bytes] = lambda mol: mol.ToBinary(propertyFlags=0b00010111)\n",
    "        result['unmin_binary'] = binarize(v.monster.positioned_mol)\n",
    "        result['min_binary'] = binarize(v.minimised_mol)\n",
    "        return result\n",
    "        # v.make_pse()\n",
    "    except Exception as error:\n",
    "        name = '-'.join([mol.SetProp('_Name') for mol in hits])\n",
    "        error_msg = f'{error.__class__.__name__} {error}'\n",
    "        Victor.journal.critical(f'*** {error_msg} for {name}')\n",
    "        return dict(error=error_msg, name=name)\n",
    "\n",
    "# =============================================================================================\n",
    "# ## Iterate\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import itertools, random, re\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "\n",
    "#@markdown How many processes to use?\n",
    "#@markdown 0 = use `multiprocessing.cpu_count()`\n",
    "#@markdown 1 = single\n",
    "n_cores = 1 #@param {type:\"integer\"}\n",
    "if n_cores < 1:\n",
    "    n_cores = cpu_count()\n",
    "    print(f'Using {n_cores} processes')\n",
    "pool = Pool(n_cores, maxtasksperchild=1)\n",
    "\n",
    "# https://github.com/matteoferla/Fragmenstein/blob/master/documentation/mol_properties.md\n",
    "# the mol is binarised... to make it pickleable...\n",
    "binarize : Callable[[Chem.Mol], bytes] = lambda mol: mol.ToBinary(propertyFlags=0b00010111)\n",
    "\n",
    "# permutations of {A,B} are AB\n",
    "# combinations of {A,B} are AB and BA\n",
    "# products of {A,B} are AA AB BA BB\n",
    "results = pool.map(combine_subprocess, itertools.permutations(map(binarize, hits), 2))\n",
    "combinations = pd.DataFrame(results)\n",
    "# =============================================================================================\n",
    "# ## plot results\n",
    "\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "def assign_ddG(value: float):\n",
    "    if str(value) == str(float('nan')):\n",
    "        return 'crashed'\n",
    "    elif value >= 0:\n",
    "        return 'unstable'\n",
    "    else:\n",
    "        return 'stable'\n",
    "\n",
    "x = pd.DataFrame(dict(\n",
    "                  rejection = combinations.disregarded.apply(len).astype(bool).map({True: 'too distant', False: 'close'}),\n",
    "                  ddG = combinations['∆∆G'].apply(assign_ddG),\n",
    "                  errored = combinations['error'].apply(len).astype(bool).map({True: 'crashed', False: 'successful'}),\n",
    "                  deviant = (combinations.comRMSD > 1).map({True: 'deviant', False: 'fixed'}),\n",
    "                  acceptable=((combinations.comRMSD < 1) \\\n",
    "                              & (combinations['∆∆G'] < 0) \\\n",
    "                             & (~combinations.disregarded.apply(len))\n",
    "                             ).map({True: 'accept', False: 'reject'})\n",
    "                     ))\\\n",
    ".value_counts('rejection\terrored\tddG\tdeviant acceptable'.split())\n",
    "summary = x.index.to_frame().reset_index(drop=True)\n",
    "summary['counts'] = x.values\n",
    "summary_fig = px.sunburst(summary,\n",
    "                    title=f'Outcome of {len(combinations)} combinations',\n",
    "                    path='errored\trejection\tddG\tdeviant acceptable'.split(), \n",
    "                    color='acceptable',\n",
    "                    color_discrete_map={'(?)':'lightgrey', \n",
    "                                        'accept':'turquoise', \n",
    "                                        'reject':'coral'},\n",
    "                    values='counts')\n",
    "summary_fig.show()\n",
    "\n",
    "# =============================================================================================\n",
    "# ## Reverse the warhead...\n",
    "# this is really unusual and janky way of doing it as one ought to know the metadata already...\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from fragmenstein import Victor\n",
    "from typing import *\n",
    "\n",
    "def reverse_warhead(smiles) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Going backwards!\n",
    "    \"\"\"\n",
    "    if not row.smiles or '*' not in row.smiles:\n",
    "        ret\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    warhead_defs = []\n",
    "    for warhead_def in Victor.warhead_definitions:\n",
    "        if mol.HasSubstructMatch( Chem.MolFromSmiles(warhead_def['covalent'])):\n",
    "            warhead_defs.append(warhead_def)\n",
    "    if not warhead_defs:\n",
    "        raise ValueError(f'Could not match {smiles} to a warhead definition in `Victor.warhead_definitions`')\n",
    "    # most complex one first!\n",
    "    warhead_def = sorted(warhead_defs, key= lambda d: -len(d['covalent_atomnames']))[0]\n",
    "    unrxn_mol = AllChem.ReplaceSubstructs(mol=mol,\n",
    "                                  query=Chem.MolFromSmiles(warhead_def['covalent']),\n",
    "                                  replacement=Chem.MolFromSmiles(warhead_def['noncovalent'])\n",
    "                                 )\n",
    "    return Chem.MolToSmiles(unrxn_mol[0]), warhead_def['name']\n",
    "\n",
    "warhead_names = []\n",
    "unreacted_smiles = []\n",
    "for i, row in combinations.iterrows():\n",
    "    unrxn, wn = reverse_warhead(smiles)\n",
    "    warhead_names.append(wn)\n",
    "    unreacted_smiles.append(unrxn)\n",
    "        \n",
    "combinations['unreacted_smiles'] = unreacted_smiles\n",
    "combinations['warhead_type'] = warhead_names\n",
    "combinations['LE'] = combinations.apply(lambda row: row['∆∆G']/(row.N_constrained_atoms+row.N_unconstrained_atoms),\n",
    "                                        axis=1)\n",
    "combinations.to_csv('combinations.csv')\n",
    "\n",
    "# =============================================================================================\n",
    "# ## top 10\n",
    "\n",
    "best_conbinations = combinations.loc[\n",
    "                (combinations.comRMSD < 1) \\\n",
    "                & (combinations['∆∆G'] < 0) \\\n",
    "                & (~combinations.disregarded.apply(len))\n",
    "                ].sort_values('LE').reset_index(drop=True).head(10)\n",
    "print('Top 10 mergers/linkers sorted by ligand efficiency')\n",
    "#PandasTools.AddMoleculeColumnToFrame(best_conbinations,'smiles','molecule',includeFingerprints=False)\n",
    "display(best_conbinations.drop(['unmin_binary', 'min_binary']))\n",
    "\n",
    "# =============================================================================================\n",
    "# ### Place purchaisable similars\n",
    "\n",
    "from smallworld_api import SmallWorld\n",
    "from warnings import warn\n",
    "\n",
    "def get_similars_df(row: pd.Series, db='REAL_DB_20Q2') -> Union[None, pd.DataFrame]:\n",
    "    try:\n",
    "        sws = SmallWorld()\n",
    "        similars : pd.DataFrame = sws.search(row.unreacted_smiles, dist=25, db=db)\n",
    "        similars['name'] = similars.hitSmiles.str.split(expand=True)[1]\n",
    "        similars['inspirations'] = [row.regarded] * len(similars)\n",
    "        similars['merger'] = [row.smiles] * len(similars)\n",
    "        similars['merger_∆∆G'] = row['∆∆G']\n",
    "        similars[['smiles', 'name', 'topodist','inspirations', 'merger', 'merger_∆∆G']]\n",
    "        similars['merger_unmin_binary'] = row.unmin_binary\n",
    "        similars['merger_min_binary'] = row.min_binary\n",
    "        return similars\n",
    "    except Exception as error:\n",
    "        warn(f'{error.__class__.__name__}: {error} for {row.smiles}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def place_subprocess(data):\n",
    "    smiles :str = data['smiles']\n",
    "    # for smallworld placements this is the unminised, not the original hits\n",
    "    # as sw query was with the former not latter\n",
    "    hits : List[Chem.Mol] = [Chem.Mol(bh) for bh in data['binary_hits']]\n",
    "    long_name : str = data['long_name']\n",
    "    pyrosetta.distributed.maybe_init(extra_options='-no_optH false -mute all -ignore_unrecognized_res true -load_PDB_components false')\n",
    "    try:\n",
    "        v = Victor(hits=hits,\n",
    "                   pdb_block=pdbblock, # global()\n",
    "                   ligand_resn='LIG',\n",
    "                   ligand_resi='1B',\n",
    "                   covalent_resi='145A', # a random residue is **still** required for the constaint ref atom.\n",
    "                  )\n",
    "        v.place(smailes=smiles, long_name=long_name)\n",
    "        result : dict = v.summarise()\n",
    "        binarize : Callable[[Chem.Mol], bytes] = lambda mol: mol.ToBinary(propertyFlags=0b00010111)\n",
    "        result['unmin_binary'] = binarize(v.monster.positioned_mol)\n",
    "        result['min_binary'] = binarize(v.minimised_mol)\n",
    "        return result\n",
    "    except Exception as error:\n",
    "        error_msg = f'{error.__class__.__name__} {error}'\n",
    "        Victor.journal.critical(f'*** {error_msg} for {long_name}')\n",
    "        return dict(error=error_msg, name=long_name)\n",
    "\n",
    "def get_data(row: pd.Series, use_unminised_combination=True) -> dict:\n",
    "    data = dict(smiles=row.smiles,\n",
    "               binary_hits=[],\n",
    "               long_name=row.name)\n",
    "    if use_unminised_combination:\n",
    "        binary_hits.append( row.merger_unmin_binary )\n",
    "    else:\n",
    "        for name in row.inspirations:\n",
    "            for hit in hits: # global #type: Chem.Mol\n",
    "                if hit.GetProp('_Name') == name:\n",
    "                    binary_hits.append( binarize(hit) )\n",
    "    return data\n",
    "    \n",
    "similars = pd.concat(objs=[get_similars_df(row) for i, row in best_conbinations.iterrows()],\n",
    "                     ignore_index=True, axis=0)\n",
    "display(similars)\n",
    "\n",
    "results = pool.map(combine_subprocess, similars.apply(get_data, axis=1).to_list())\n",
    "placements = pd.DataFrame(results)\n",
    "placements.to_csv('placements.csv')\n",
    "display(placements)\n",
    "placements['const_ratio'] = placements['N_constrained_atoms']/(placements['N_constrained_atoms']+placements['N_unconstrained_atoms'])\n",
    "\n",
    "placements['hit_mols'] = None\n",
    "placements['merger_unminimized_mol'] = None\n",
    "placements['merger_minimized_mol'] = None\n",
    "\n",
    "best_placements = placements.loc[\n",
    "                (placements.comRMSD < 1) \\\n",
    "                & (placements['∆∆G'] < 0) \\\n",
    "                & (placements.const_ratio > 2/3) \\  # more than 2 in 3 is actually uncommon\n",
    "                & (~placements.disregarded.apply(len))\n",
    "                ].sort_values('LE').reset_index(drop=True).head(10)\n",
    "print('Top 10 placements sorted by ligand efficiency')\n",
    "#PandasTools.AddMoleculeColumnToFrame(best_conbinations,'smiles','molecule',includeFingerprints=False)\n",
    "display(best_placements.drop(['hit_mols', 'merger_unminimized_mol', 'merger_unminimized_mol', 'unmin_binary', 'min_binary'])\n",
    "\n",
    "# =============================================================================================\n",
    "# ### Results redux\n",
    "\n",
    "from IPython.display import clear_output, HTML, display\n",
    "headerify : Callable[[str], HTML] = lambda header: HTML(f'<h3>{header}</h3>)\n",
    "clear_output()\n",
    "display(headerify('Provided hits'))\n",
    "HorizontalMols(hits)\n",
    "display(headerify('Step 1. Combine'))                                 \n",
    "summary_fig.show()\n",
    "print('Top 10 mergers/linkers sorted by ligand efficiency')\n",
    "display(best_conbinations.drop(['unmin_binary', 'min_binary']))\n",
    "display(headerify('Step 2. Placement of purchasable similars'))                            \n",
    "#display(similars)\n",
    "display(headerify('Top 10 Placements'))\n",
    "display(best_placements.drop(['unmin_binary', 'min_binary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Inspect specific\n",
    "\n",
    "# from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import PandasTools\n",
    "#PandasTools.AddMoleculeColumnToFrame(best_conbinations,'smiles','molecule',includeFingerprints=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
